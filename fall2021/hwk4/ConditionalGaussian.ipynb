{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b86680e9-bb74-45c0-b035-a1a3f37093a5",
   "metadata": {},
   "source": [
    "2.1 Gaussian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2e2edd08-149e-4ff9-9565-b1593554fecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Question 2.0 Skeleton Code\n",
    "\n",
    "Here you should load the data and plot\n",
    "the means for each of the digit classes.\n",
    "'''\n",
    "\n",
    "import data\n",
    "import numpy as np\n",
    "# Import pyplot - plt.imshow is useful!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_means(train_data, train_labels):\n",
    "    means = []\n",
    "    for i in range(0, 10):\n",
    "        i_digits = data.get_digits_by_label(train_data, train_labels, i)\n",
    "        # Compute mean of class i\n",
    "        # [0, 1, 0, 0, 1 ... ]in total 700 rows each with 64 columns\n",
    "        i_digits = np.mean(i_digits, axis=0)\n",
    "        means.append( i_digits.reshape((8,8)) )\n",
    "\n",
    "    # Plot all means on same axis\n",
    "    #print(\"means: \",means[0].shape)\n",
    "    all_concat = np.concatenate(means, 1)\n",
    "    plt.imshow(all_concat, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_data, train_labels, _, _ = data.load_all_data_from_zip('a4digits.zip', 'data')\n",
    "    plot_means(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "59d10f76-3480-43b8-8b94-7000d02b78d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1 Plot the log-diagonal of each covariance matrix side by side\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "2.1.2 Compute the average conditional log-likelihood\n",
      "For the training set:\n",
      "The average conditional likelihood in the training set is: -0.12462443666863002\n",
      "For the test set:\n",
      "The average conditional likelihood in the test set is: -0.1966732032552562\n",
      "===================\n",
      "2.1.3 Select the most likely posterior class for each training and test data point\n",
      "Accuracy: 0.9814285714285714\n",
      "Accuracy: 0.97275\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Question 2.1 Skeleton Code\n",
    "\n",
    "Here you should implement and evaluate the Conditional Gaussian classifier.\n",
    "'''\n",
    "\n",
    "import data\n",
    "import numpy as np\n",
    "# Import pyplot - plt.imshow is useful!\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "\n",
    "def compute_mean_mles(train_data, train_labels):\n",
    "    '''\n",
    "    Compute the mean estimate for each digit class\n",
    "\n",
    "    Should return a numpy array of size (10,64)\n",
    "    The ith row will correspond to the mean estimate for digit class i\n",
    "    '''\n",
    "    # Compute means\n",
    "    tmp = []\n",
    "    for i in range(10):\n",
    "        i_digits = data.get_digits_by_label(train_data, train_labels, i)\n",
    "        tmp.append( np.mean(i_digits, axis=0) )\n",
    "        \n",
    "    # Create array from list \"tmp\"\n",
    "    means = np.array(tmp) # (10,64)\n",
    "    return means\n",
    "\n",
    "def compute_sigma_mles(train_data, train_labels):\n",
    "    '''\n",
    "    Compute the covariance estimate for each digit class\n",
    "\n",
    "    Should return a three dimensional numpy array of shape (10, 64, 64)\n",
    "    consisting of a covariance matrix for each digit class \n",
    "    '''\n",
    "    covariances = np.zeros((10, 64, 64))\n",
    "    mu = compute_mean_mles(train_data, train_labels)# (10,64)\n",
    "    \n",
    "    for i in range(10):\n",
    "        i_digits = data.get_digits_by_label(train_data, train_labels, i) # (700,64)\n",
    "        X = i_digits\n",
    "        N = X.shape[0]\n",
    "        covariances[i,:,:] = np.matmul( (X - mu[i,:]).T,(X - mu[i,:]) )/ N        \n",
    "        idmx = np.zeros((64,64))\n",
    "        np.fill_diagonal(idmx, 1)\n",
    "        covariances[i,:,:] = covariances[i,:,:] + 0.01 * idmx    \n",
    "    return covariances\n",
    "\n",
    "def plot_cov_diagonal(covariances):\n",
    "    # Plot the log-diagonal of each covariance matrix side by side\n",
    "    diag = []\n",
    "    for i in range(10):\n",
    "        cov_diag = np.diag(covariances[i])\n",
    "        log_diag = np.log(cov_diag)\n",
    "        diag.append( log_diag.reshape((8,8)) )\n",
    "                \n",
    "    all_concat = np.concatenate(diag, 1)\n",
    "    plt.imshow(all_concat, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "def generative_likelihood(digits, means, covariances):\n",
    "    '''\n",
    "    Compute the generative log-likelihood:\n",
    "        log p(x|y,mu,Sigma)\n",
    "\n",
    "    Should return an n x 10 numpy array \n",
    "    '''\n",
    "    likelihood = np.zeros((digits.shape[0],10))    \n",
    "    X = digits # shape (700,64)\n",
    "    mu = means # shape (10,64)\n",
    "    d = X.shape[1] # dimensions\n",
    "    \n",
    "    for n in range(X.shape[0]): # n is a sample of the data or row\n",
    "        for k in range(10): # k is a class or label\n",
    "            first_term = -(d/2)*np.log(2*np.pi) \n",
    "            second_term = -(1/2)*np.log(np.linalg.det(covariances[k,:,:])) \n",
    "            third_term = -(1/2)*np.dot( np.dot( (X[n,:] - mu[k,:]).T, np.linalg.inv(covariances[k,:,:])) , (X[n,:] - mu[k,:]))\n",
    "            likelihood[n,k] = first_term + second_term + third_term\n",
    "    return likelihood\n",
    "    \n",
    "def conditional_likelihood(digits, means, covariances):\n",
    "    '''\n",
    "    Compute the conditional likelihood:\n",
    "\n",
    "        log p(y|x, mu, Sigma)\n",
    "\n",
    "    This should be a numpy array of shape (n, 10)\n",
    "    Where n is the number of datapoints and 10 corresponds to each digit class\n",
    "    '''\n",
    "    # From:\n",
    "    # log p(y|x, mu, Sigma) = log p(x|y) + log p(y) - log p(x) (slide 59)\n",
    "    n = digits.shape[0]\n",
    "    condit_likellihood = np.zeros((n, 10))\n",
    "    log_prob_x_y = generative_likelihood(digits, means, covariances)\n",
    "    from scipy.special import logsumexp\n",
    "    for s in range(n):\n",
    "        condit_likellihood[s,:] = log_prob_x_y[s,:] - logsumexp(log_prob_x_y[s,:])\n",
    "    return condit_likellihood\n",
    "\n",
    "def avg_conditional_likelihood(digits, labels, means, covariances):\n",
    "    '''\n",
    "    Compute the average conditional likelihood over the true class labels\n",
    "\n",
    "        AVG( log p(y_i|x_i, mu, Sigma) )\n",
    "\n",
    "    i.e. the average log likelihood that the model assigns to the correct class label\n",
    "    '''\n",
    "    set_type = \"\"\n",
    "    size_set = digits.shape[0]\n",
    "    if size_set == 7000:\n",
    "        set_type = \"training\"\n",
    "    elif size_set == 4000:\n",
    "        set_type = \"test\"\n",
    "        \n",
    "    condition_likelihood = conditional_likelihood(digits, means, covariances)\n",
    "    sum_lik = 0\n",
    "    for idx in range(size_set):\n",
    "        sum_lik = sum_lik + condition_likelihood[idx, int(labels[idx])]\n",
    "    \n",
    "    print(\"For the {} set:\".format(set_type))\n",
    "    print(\"The average conditional likelihood in the {} set is: {}\".format(set_type, sum_lik/size_set))\n",
    "    return sum_lik/size_set\n",
    "\n",
    "def accuracy_classify_data(most_likely_class, ground_truth):\n",
    "    '''\n",
    "    Compute the accuracy of the classification task\n",
    "    '''\n",
    "    accuracy = np.mean(most_likely_class == ground_truth)\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "\n",
    "def classify_data(digits, means, covariances):\n",
    "    '''\n",
    "    Classify new points by taking the most likely posterior class\n",
    "    '''\n",
    "    cond_likelihood = conditional_likelihood(digits, means, covariances) # (n,10)\n",
    "    # Compute and return the most likely class\n",
    "    most_likely = np.argmax(cond_likelihood, axis=1)\n",
    "    return most_likely\n",
    "\n",
    "def main():\n",
    "    train_data, train_labels, test_data, test_labels = data.load_all_data('data')\n",
    "\n",
    "    # Fit the model\n",
    "    means = compute_mean_mles(train_data, train_labels)\n",
    "    covariances = compute_sigma_mles(train_data, train_labels)\n",
    "    \n",
    "    print(\"2.1.1 Plot the log-diagonal of each covariance matrix side by side\")\n",
    "    plot_cov_diagonal(covariances)\n",
    "\n",
    "    print(\"===================\")\n",
    "    print(\"2.1.2 Compute the average conditional log-likelihood\")\n",
    "    avg_conditional_likelihood(train_data, train_labels, means, covariances)\n",
    "    avg_conditional_likelihood(test_data, test_labels, means, covariances)\n",
    "    \n",
    "    print(\"===================\")\n",
    "    print(\"2.1.3 Select the most likely posterior class for each training and test data point\")\n",
    "    training_most_likely_class = classify_data(train_data, means, covariances)\n",
    "    accuracy_classify_data(training_most_likely_class, train_labels)\n",
    "    \n",
    "    test_most_likely_class = classify_data(test_data, means, covariances)\n",
    "    accuracy_classify_data(test_most_likely_class, test_labels)\n",
    "    # Evaluation\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e9b74-5c3d-4e6f-91f7-1ae854393cea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6613dbf6-d190-4535-b7c5-5fff88d098dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b3c472-7731-4f2a-80da-713967819bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
